{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST on SageMaker with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset to local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_DATA_BUCKET = 'dataset.mnist'\n",
    "S3_TRAINING_DATA = S3_DATA_BUCKET+'/training'\n",
    "S3_TESTING_DATA = S3_DATA_BUCKET+'/testing'\n",
    "\n",
    "DATA_PATH = '../dataset'\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!mkdir -p $DATA_PATH/training\n",
    "#!mkdir -p $DATA_PATH/testing\n",
    "#!aws s3api get-object --bucket $S3_DATA_BUCKET --key mnist.tar.gz $DATA_PATH/mnist.tar.gz\n",
    "#!cd $DATA_PATH && tar xvf mnist.tar.gz && rm -f mnist.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install libraries if not already installed\n",
    "! pip install torch\n",
    "! pip install torchvision\n",
    "! pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install libraries specific for Jupyter Notebook\n",
    "! pip install ipywidgets\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random as rn\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries specific for Jupyter notebook visualization\n",
    "from matplotlib import pyplot as plt, image\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = DATA_PATH+'/training'\n",
    "dataset = datasets.ImageFolder(train_data_dir)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [55000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few images to have an idea about the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(image.imread(train_set.dataset.imgs[0][0]))\n",
    "plt.figure()\n",
    "plt.imshow(image.imread(train_set.dataset.imgs[7000][0]))\n",
    "plt.figure()\n",
    "plt.imshow(image.imread(train_set.dataset.imgs[20000][0]))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix random seed\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed(2020)\n",
    "torch.cuda.manual_seed_all(2020)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "epochs = 10\n",
    "validation_size = .3\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = DATA_PATH+'/training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv_layer_1 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(3,28, kernel_size=5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.conv_layer_2 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(28,10, kernel_size=2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.dropout1=torch.nn.Dropout(0.25)\n",
    "        self.fully_connected_1=torch.nn.Linear(250,18)\n",
    "        self.dropout2=torch.nn.Dropout(0.08)\n",
    "        self.fully_connected_2=torch.nn.Linear(18,10)\n",
    "\n",
    "    def load_split_train_test(datadir, valid_size = .2):\n",
    "        train_transforms = transforms.Compose([T.RandomHorizontalFlip(),                                       \n",
    "                                           T.ToTensor(),\n",
    "                                           T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "        test_transforms = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "        train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n",
    "        test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n",
    "\n",
    "        num_train = len(train_data)\n",
    "        indices = list(range(num_train))\n",
    "        split = int(np.floor(valid_size * num_train))\n",
    "        np.random.shuffle(indices)\n",
    "        from torch.utils.data.sampler import SubsetRandomSampler\n",
    "        train_idx, test_idx = indices[split:], indices[:split]\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        test_sampler = SubsetRandomSampler(test_idx)\n",
    "        trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, num_workers=num_workers)\n",
    "        testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=batch_size, num_workers=num_workers)\n",
    "        return trainloader, testloader\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.train_loader, self.val_loader = load_split_train_test(data_dir, validation_size)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.val_loader\n",
    "    \n",
    "#    def test_dataloader(self):\n",
    "#        return DataLoader(MNIST(os.getcwd(), train=False, download=False, transform=transform.ToTensor()), batch_size=128)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv_layer_1(x)\n",
    "        x=self.conv_layer_2(x)\n",
    "        x=self.dropout1(x)\n",
    "        x=torch.relu(self.fully_connected_1(x.view(x.size(0),-1)))\n",
    "        x=F.leaky_relu(self.dropout2(x))\n",
    "        return F.softmax(self.fully_connected_2(x), dim=1)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        # Get input and output from batch\n",
    "        x, labels = batch\n",
    "        \n",
    "        # Compute prediction through the network\n",
    "        prediction = self.forward(x)\n",
    "        \n",
    "        loss = F.nll_loss(prediction, labels)\n",
    "        \n",
    "        # Logs training loss\n",
    "        logs={'train_loss':loss}\n",
    "        \n",
    "        output = {\n",
    "            # This is required in training to be used by backpropagation\n",
    "            'loss':loss,\n",
    "            # This is optional for logging pourposes\n",
    "            'log':logs\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, labels = batch\n",
    "        prediction = self.forward(x)\n",
    "        return {\n",
    "            'val_loss': F.cross_entropy(prediction, labels)\n",
    "        }\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss_mean = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        return {'val_loss': val_loss_mean}\n",
    "\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        print('Average training loss: '+str(avg_loss.item()))\n",
    "        logs = {'val_loss':avg_loss}\n",
    "        return {\n",
    "            'avg_val_loss':avg_loss,\n",
    "            'log':logs\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The trainer abstracts training, validation and test loops\n",
    "\n",
    "mnistTrainer=pl.Trainer(gpus=1, max_epochs=epochs)\n",
    "\n",
    "model = MNISTClassifier()\n",
    "mnistTrainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
